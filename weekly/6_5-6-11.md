# Weekly note 6/5 - 6/11

## Delivered this week

- Experiment the integration of <strike>nfd</strike> tfd
    - [x] Pending [PR #11717 Add filepicker](https://github.com/servo/servo/pull/11717)
- Blob URL:
    - [x] Landed [PR #11536 Add blob loader](https://github.com/servo/servo/pull/11536)
    - [x] Pending [PR #11716 Implement Blob URL's DOM interfaces](https://github.com/servo/servo/pull/11716)
- More improvements and testings:
    - [x] Land [Improve implementation and add testing regarding file manager thread #11552](https://github.com/servo/servo/pull/11552)
    - [ ] HTML input element related (some changes are bundled in PR #11716)
    - [x] `DataSlice` related
        - [PR #11711 Improve unit test of DataSlice](https://github.com/servo/servo/pull/11711)
- Track the `Origin` dependency
    - Part of the newly proposed design is implemented across PR #11536 and PR #11552. Need continued tracking though.
- Track `ArrayBuffer` dependency
    - Still not exposed to DOM interface AFAIK

## Talk with Gecko file guy

src: http://logs.glob.uno/?c=mozilla%23content&s=8+Jun+2016&e=8+Jun+2016

### About ownership of Blob
baku: Usually Blobs live in the process where they are created, for instances if you do: `new Blob([123]);` that blob stays there. but if these blobs/files are generated by a FilePicker or from a IDB or if you send them using some IPC-based API (BroadcastChannel, messagePort, SharedWorkers, IDB, etc), they live in the parent process as well. We have this `RemoteBlobImpl` that does the magic. So, the answer is: they live in the process where they have been created, but they can change 

### About *caching* of data
baku: we cache some information, mimetype and fileSize. Files are immutable by spec. in fact we have some bugs about invalidating File objects if the underlying OS file changes.

baku: For instance if you have a filepicker, I take the file from the `<input type="file"/>`, then I create a slice and I have a `file2`. now the underlying file changes, what does it happen to `file2`? Should it be invalidated? should it be still active? the spec doesn't talk about that


baku: at least, would be nice to have: `file.onchange = ...`.


Manishearth: gecko and blink both just pick up new changes (and empty the blob if it was a slice to an out of bounds error)


### When you send to script, do you share a readonly file descriptor over the socket, or take a snapshot of bytes into memory and copy over?

baku: you can retrieve a `nsIInputStream`, this is the only thing you have to retrieve data, because often a `Blob` is not a 'real' file. You ask the 'owning' process to read it for you. and for a OS File, this process is always the parent process.

### What will happen if a slice is passed to Blob URL creation?
baku: internally we have a `BlobImpl` class and we have multiple classes inheriting that `BlobImpl`, based on the 'nature' of the Blob,  Memory, Temporary, File, Empty, Multipart, etc. Each one of them has its own implementation of `Slice`. when you create a `Slice`, the different nature's of `BlobImpl`, create other `BlobImpl`s.

baku: For File, for instance, we keep a refernece to `nsCOMPtr<nsIFile>` plus the starting point and the offset; for Memory we do something similar but using the buffer. Empty does nothing. `RemoteBlobImpl` does something "completely" different. 

baku: we have a `nsBlobProtocolHandler` that is in charge to keep 'alive' a blob URL, storing the `BlobImpl` and the URL associated with it


baku to izgzhen: you can find all the implementations in `dom/base/File.{h,cpp}`


### IDB

    8:35 PM <baku> Manishearth: what about if you store a blob in IDB ?
    8:36 PM <Manishearth> baku: uh
    8:36 PM <Manishearth> baku: that's structured clone, right?
    8:36 PM <baku> and then you retrieve it at the next refresh of the page... ?
    8:36 PM <Manishearth> if IDB uses structured clone, just read the whole blob and store that bucket of bits in the IDB
    8:37 PM <baku> Manishearth: we clone blobs, yes
    8:37 PM <baku> but they are not serialized in the StructuredCloneAlgorithm
    8:37 PM <Manishearth> so...what happens?
    8:37 PM <baku> we keep a reference to them and we keep the BlobImpl alive until the 'read' is done.
    8:37 PM <baku> then, we serialize the Blob into a File in the quotaManager folder for that origin and we store stuff in IDB
    8:38 PM <Manishearth> > and we keep the BlobImpl alive until the 'read' is done
    8:38 PM <Manishearth> I'm not really sure why this is necessary -- why wouldn't it be alive?
    8:38 PM <Manishearth> oh, serializing to a file is a good idea
    8:38 PM <Manishearth> baku: note that for now we don't have IDB :)
    8:39 PM <baku> Manishearth: because maybe you are sending something via StructuredCloneAlgorithm and the 'parent' is CCed/GCed in the meantime. or just the blob is CCed/GCed.
    8:39 PM <baku> for instance: a worker can do: var a = new Blob([123]); postMessage(a); a=null; do_Something_so_that_we_GC_everything();
    8:39 PM <baku> and in the meantime the main-thread is superbusy
    8:39 PM <Manishearth> baku: oh, right, y'all have the CC
    8:40 PM <baku> when we do onmessage, the blob must still exist :)
    8:40 PM <Manishearth> baku: we can just pass around Root<Blob> and everything is dandy
    8:40 PM <Manishearth> or Trusted<Blob> in case of threads
    8:40 PM <baku> heheh nice thing :)
    8:40 PM <baku> so yeah, IDB -> serialize to file, next time we create a Blob pointing to that file. done :)
